{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Toy TS Training for Deep3D+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple tester for the deep3d\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import Deep3D_branched as deep3d\n",
    "import utils\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import h5py\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data from H5 Format for fast loading\n",
    "- Will eventually unit test dynamic CPU data loading pipeline here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size:(3500, 160, 288, 3)\n",
      "Validation Size:(443, 160, 288, 3)\n"
     ]
    }
   ],
   "source": [
    "inria_file = '/a/data/deep3d_data/inria_data.h5'\n",
    "# inria_file = 'data/inria_data.h5'\n",
    "h5f = h5py.File(inria_file,'r')\n",
    "\n",
    "X_train_0 = h5f['X_0'][:,10:170,16:304,:]\n",
    "Y_train_0 = h5f['Y_0'][:,10:170,16:304,:]\n",
    "X_train_1 = h5f['X_1'][:,10:170,16:304,:]\n",
    "Y_train_1 = h5f['Y_1'][:,10:170,16:304,:]\n",
    "X_train_2 = h5f['X_2'][:,10:170,16:304,:]\n",
    "Y_train_2 = h5f['Y_2'][:,10:170,16:304,:]\n",
    "X_train_3 = h5f['X_3'][:,10:170,16:304,:]\n",
    "Y_train_3 = h5f['Y_3'][:,10:170,16:304,:]\n",
    "X_train_4 = h5f['X_4'][:,10:170,16:304,:]\n",
    "Y_train_4 = h5f['Y_4'][:,10:170,16:304,:]\n",
    "X_train_5 = h5f['X_5'][:,10:170,16:304,:]\n",
    "Y_train_5 = h5f['Y_5'][:,10:170,16:304,:]\n",
    "X_train_6 = h5f['X_6'][:,10:170,16:304,:]\n",
    "Y_train_6 = h5f['Y_6'][:,10:170,16:304,:]\n",
    "#X_train_7 = h5f['X_7'][:,10:170,16:304,:]\n",
    "#Y_train_7 = h5f['Y_7'][:,10:170,16:304,:]\n",
    "\n",
    "\n",
    "X_val = h5f['X_7'][:,10:170,16:304,:]\n",
    "Y_val = h5f['Y_7'][:,10:170,16:304,:]\n",
    "  \n",
    "h5f.close()\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------#\n",
    "X_train = np.concatenate([X_train_0,X_train_1,X_train_2,X_train_3,X_train_4,X_train_5,X_train_6])\n",
    "Y_train = np.concatenate([Y_train_0,Y_train_1,Y_train_2,Y_train_3,Y_train_4,Y_train_5,Y_train_6])\n",
    "\n",
    "print \"Training Size:\" + str(X_train.shape)\n",
    "print \"Validation Size:\" + str(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable count:\n",
      "139063583\n",
      "\n",
      "== Start training ==\n",
      "(0/162)    | Cost: 12277.1\n",
      "(1/162)    | Cost: 9202.23\n",
      "(2/162)    | Cost: 8189.46\n",
      "(3/162)    | Cost: 8614.69\n",
      "(4/162)    | Cost: 8098.2\n",
      "(5/162)    | Cost: 8203.87\n",
      "(6/162)    | Cost: 7643.63\n",
      "(7/162)    | Cost: 8911.97\n",
      "(8/162)    | Cost: 7444.71\n",
      "(9/162)    | Cost: 7882.08\n",
      "(10/162)   | Cost: 7743.14\n",
      "(11/162)   | Cost: 7741.81\n",
      "(12/162)   | Cost: 8068.62\n",
      "(13/162)   | Cost: 8914.06\n",
      "(14/162)   | Cost: 8087.85\n",
      "(15/162)   | Cost: 7135.56\n",
      "(16/162)   | Cost: 7467.24\n",
      "(17/162)   | Cost: 8208.4\n",
      "(18/162)   | Cost: 7888.25\n",
      "(19/162)   | Cost: 6983.28\n",
      "(20/162)   | Cost: 7840.61\n",
      "(21/162)   | Cost: 8272.17\n",
      "(22/162)   | Cost: 8900.15\n",
      "(23/162)   | Cost: 8055.81\n",
      "(24/162)   | Cost: 8751.43\n",
      "(25/162)   | Cost: 8451.68\n",
      "(26/162)   | Cost: 7665.87\n",
      "(27/162)   | Cost: 8102.41\n",
      "(28/162)   | Cost: 7906.55\n",
      "(29/162)   | Cost: 8806.08\n",
      "(30/162)   | Cost: 8369.04\n",
      "(31/162)   | Cost: 7368.95\n",
      "(32/162)   | Cost: 8144.27\n",
      "(33/162)   | Cost: 7734.42\n",
      "(34/162)   | Cost: 7909.18\n",
      "(35/162)   | Cost: 8499.65\n",
      "(36/162)   | Cost: 7371.16\n",
      "(37/162)   | Cost: 8174.73\n",
      "(38/162)   | Cost: 8360.66\n",
      "(39/162)   | Cost: 7882.39\n",
      "(40/162)   | Cost: 8450.63\n",
      "(41/162)   | Cost: 8067.71\n",
      "(42/162)   | Cost: 7047.52\n",
      "(43/162)   | Cost: 8068.38\n",
      "(44/162)   | Cost: 7827.91\n",
      "(45/162)   | Cost: 7670.14\n",
      "(46/162)   | Cost: 7919.62\n",
      "(47/162)   | Cost: 9112.23\n",
      "(48/162)   | Cost: 7605.25\n",
      "(49/162)   | Cost: 8815.21\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[64,160,288,3,33]\n\t [[Node: gradients/select/Mul_grad/mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/select/Sum_grad/Tile, select/ExpandDims)]]\n\nCaused by op u'gradients/select/Mul_grad/mul', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-d2a1efbf94c5>\", line 39, in <module>\n    train = tf.train.GradientDescentOptimizer(0.002).minimize(cost)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 315, in minimize\n    grad_loss=grad_loss)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 386, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 368, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 625, in _MulGrad\n    return (array_ops.reshape(math_ops.reduce_sum(grad * y, rx), sx),\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 821, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1044, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1434, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'select/Mul', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 18 identical lines from previous traceback]\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-d2a1efbf94c5>\", line 23, in <module>\n    net.build(images, train_mode)\n  File \"Deep3D_branched.py\", line 147, in build\n    self.prob  = selection.select(self.mask, rgb)\n  File \"selection.py\", line 30, in select\n    disparity_image = tf.multiply(slices, tf.expand_dims(masks, axis=3))\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 278, in multiply\n    return gen_math_ops._mul(x, y, name)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1434, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,160,288,3,33]\n\t [[Node: gradients/select/Mul_grad/mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/select/Sum_grad/Tile, select/ExpandDims)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d2a1efbf94c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Traing Step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimages_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_out\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabels_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[64,160,288,3,33]\n\t [[Node: gradients/select/Mul_grad/mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/select/Sum_grad/Tile, select/ExpandDims)]]\n\nCaused by op u'gradients/select/Mul_grad/mul', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib64/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-d2a1efbf94c5>\", line 39, in <module>\n    train = tf.train.GradientDescentOptimizer(0.002).minimize(cost)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 315, in minimize\n    grad_loss=grad_loss)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py\", line 386, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 368, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py\", line 560, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/math_grad.py\", line 625, in _MulGrad\n    return (array_ops.reshape(math_ops.reduce_sum(grad * y, rx), sx),\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 821, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1044, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1434, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op u'select/Mul', defined at:\n  File \"/usr/lib64/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n[elided 18 identical lines from previous traceback]\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-d2a1efbf94c5>\", line 23, in <module>\n    net.build(images, train_mode)\n  File \"Deep3D_branched.py\", line 147, in build\n    self.prob  = selection.select(self.mask, rgb)\n  File \"selection.py\", line 30, in select\n    disparity_image = tf.multiply(slices, tf.expand_dims(masks, axis=3))\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 278, in multiply\n    return gen_math_ops._mul(x, y, name)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1434, in _mul\n    result = _op_def_lib.apply_op(\"Mul\", x=x, y=y, name=name)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[64,160,288,3,33]\n\t [[Node: gradients/select/Mul_grad/mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](gradients/select/Sum_grad/Tile, select/ExpandDims)]]\n"
     ]
    }
   ],
   "source": [
    "batchsize = 64\n",
    "num_epochs = 3\n",
    "num_batches = (X_train.shape[0]/batchsize)*num_epochs\n",
    "print_step = 1\n",
    "viz_step = 10\n",
    "\n",
    "# Define config for GPU memory debugging \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True  # Switch to True for dynamic memory allocation instead of TF hogging BS\n",
    "config.gpu_options.per_process_gpu_memory_fraction= 1  # Cap TF mem usage\n",
    "config.allow_soft_placement=True\n",
    "with tf.device('/gpu:0'):\n",
    "    # Session\n",
    "    sess = tf.Session(config=config)\n",
    "    \n",
    "    # Placeholders\n",
    "    images = tf.placeholder(tf.float32, [None, 160, 288, 3], name='input_batch')\n",
    "    true_out = tf.placeholder(tf.float32, [None, 160, 288, 3] , name='ground_truth')\n",
    "    train_mode = tf.placeholder(tf.bool, name='train_mode')\n",
    "\n",
    "    # Building Net based on VGG weights \n",
    "    net = deep3d.Deep3Dnet('./vgg19.npy', dropout = 0.5)\n",
    "    net.build(images, train_mode)\n",
    "\n",
    "    # Print number of variables used: 143667240 variables, i.e. ideal size = 548MB\n",
    "    print 'Variable count:'\n",
    "    print(net.get_var_count())\n",
    "    \n",
    "    # Run initializer \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "    # Define Training Objectives\n",
    "    with tf.variable_scope(\"Loss\"):\n",
    "        cost = tf.reduce_sum(tf.abs(net.prob - true_out))/batchsize\n",
    "    \n",
    "    \n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):    \n",
    "        train = tf.train.GradientDescentOptimizer(0.002).minimize(cost)\n",
    "        \n",
    "    # Track Cost    \n",
    "    tf.summary.scalar('cost', cost)\n",
    "    # tensorboard operations to compile summary and then write into logs\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter('./tensorboard_logs/', graph = sess.graph)\n",
    "\n",
    "    \n",
    "    # Training Loop\n",
    "    print \"\"\n",
    "    print \"== Start training ==\"\n",
    "    for i in xrange(num_batches):\n",
    "        # Creating Batch\n",
    "        image_mask = np.random.choice(X_train.shape[0],batchsize)\n",
    "        images_in = X_train[image_mask,:,:,:]\n",
    "        labels_in = Y_train[image_mask,:,:,:]\n",
    "\n",
    "        # Traing Step\n",
    "        _, cost_val, summary = sess.run([train, cost, merged], feed_dict={images: images_in, true_out: labels_in, train_mode: True})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "        # No longer needed: cost_hist.append(cost_val)\n",
    "        if i%print_step == 0:\n",
    "            print (\"({}/{})\".format(i, num_batches).ljust(10) + ' | Cost: ' + str(cost_val))\n",
    "    \n",
    "    \n",
    "    print \"\"\n",
    "    print \"Training Completed, storing weights\"\n",
    "    # Store Traing Output\n",
    "    net.save_npy(sess)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "test_img = np.expand_dims(X_val[170], axis = 0)\n",
    "test_ans = Y_val[170]\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    res, mask, up_conv = sess.run([net.prob, net.mask, net.up_conv], \n",
    "                                  feed_dict={images: test_img, train_mode: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print \"--- Input ---\"\n",
    "plt.imshow(test_img[0])\n",
    "plt.show()\n",
    "\n",
    "print \"--- GT ---\"\n",
    "plt.imshow(test_ans)\n",
    "plt.show()\n",
    "\n",
    "print \"--- Our result ---\"\n",
    "plt.imshow(res[0])\n",
    "plt.show()\n",
    "\n",
    "#pyplot.imsave('1.jpeg', test_img[0])\n",
    "#pyplot.imsave('2.jpeg', res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Disparity Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(6, 6, sharex='col', sharey='row')\n",
    "\n",
    "for i in range(33):\n",
    "    axs[i/6][i%6].imshow(mask[0,:,:,i],cmap=\"gray\",vmin=0.0, vmax=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_shift_channel = np.argmax(mask,axis = 3)\n",
    "max_shift_channel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_mean = np.mean(mask[0], axis =(0,1))\n",
    "channel_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(channel_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_act_mean = np.mean(up_conv[0], axis =(0,1))\n",
    "plt.plot(channel_act_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(up_conv[0,:,:,16].ravel(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for layer in range(0,33):\n",
    "    plt.imshow(up_conv[0,:,:,layer],cmap=\"gray\", vmin= 0, vmax=up_conv[0,:,:,layer].max())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
