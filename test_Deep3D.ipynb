{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Toy TS Training for Deep3D+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple tester for the deep3d\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import Deep3D as deep3d\n",
    "import utils\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import h5py\n",
    "import matplotlib as plt\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data from H5 Format for fast loading\n",
    "- Will eventually unit test dynamic CPU data loading pipeline here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inria_file = '/a/data/deep3d_data/inria_data.h5'\n",
    "inria_file = 'data/inria_data.h5'\n",
    "h5f = h5py.File(inria_file,'r')\n",
    "\n",
    "X_train = h5f['X_0'][:,10:170,16:304,:]\n",
    "Y_train = h5f['Y_0'][:,10:170,16:304,:]\n",
    "# X_train_1 = h5f['X_1'][:,10:170,16:304,:]\n",
    "# Y_train_1 = h5f['Y_1'][:,10:170,16:304,:]\n",
    "# X_train_2 = h5f['X_2'][:,10:170,16:304,:]\n",
    "# Y_train_2 = h5f['Y_2'][:,10:170,16:304,:]\n",
    "# X_train_3 = h5f['X_3'][:,10:170,16:304,:]\n",
    "# Y_train_3 = h5f['Y_3'][:,10:170,16:304,:]\n",
    "\n",
    "X_val = h5f['X_4'][:,10:170,16:304,:]\n",
    "Y_val = h5f['Y_4'][:,10:170,16:304,:]\n",
    "  \n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size:(500, 160, 288, 3)\n",
      "Validation Size:(500, 160, 288, 3)\n"
     ]
    }
   ],
   "source": [
    "# X_train = np.concatenate([X_train_0,X_train_1,X_train_2,X_train_3])\n",
    "# Y_train = np.concatenate([Y_train_0,Y_train_1,Y_train_2,Y_train_3])\n",
    "\n",
    "print \"Training Size:\" + str(X_train.shape)\n",
    "print \"Validation Size:\" + str(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable count:\n",
      "138408071\n",
      "\n",
      "== Start training ==\n",
      "(0/1)      | Cost: 60336.9\n",
      "\n",
      "Training Completed, storing weights\n",
      "('file saved', './deep3d-save.npy')\n"
     ]
    }
   ],
   "source": [
    "num_batches = 1\n",
    "batchsize = 6\n",
    "print_step = 1\n",
    "#cost_hist = []\n",
    "viz_step = 10\n",
    "\n",
    "# Define config for GPU memory debugging \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True  # Switch to True for dynamic memory allocation instead of TF hogging BS\n",
    "config.gpu_options.per_process_gpu_memory_fraction= 1  # Cap TF mem usage\n",
    "\n",
    "#with tf.device('/gpu:0'):\n",
    "with tf.device('/cpu:0'):  \n",
    "    # Session\n",
    "    #sess = tf.Session(config=config)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Placeholders\n",
    "    images = tf.placeholder(tf.float32, [batchsize, 160, 288, 3], name='input_batch')\n",
    "    true_out = tf.placeholder(tf.float32, [batchsize, 160, 288, 3] , name='ground_truth')\n",
    "    train_mode = tf.placeholder(tf.bool, name='train_mode')\n",
    "\n",
    "    # Building Net based on VGG weights \n",
    "    net = deep3d.Deep3Dnet('./vgg19.npy')\n",
    "    net.build(images, train_mode)\n",
    "\n",
    "    # Print number of variables used: 143667240 variables, i.e. ideal size = 548MB\n",
    "    print 'Variable count:'\n",
    "    print(net.get_var_count())\n",
    "    \n",
    "    # Run initializer \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Define Training Objectives\n",
    "    cost = tf.reduce_sum(tf.abs(net.prob - true_out), name='L1_loss')\n",
    "    train = tf.train.GradientDescentOptimizer(0.002).minimize(cost)\n",
    "    \n",
    "    # tensorboard operations to compile summary and then write into logs\n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter('./tensorboard_logs/', graph = sess.graph)\n",
    "\n",
    "    # Training Loop\n",
    "    print \"\"\n",
    "    print \"== Start training ==\"\n",
    "    for i in xrange(num_batches):\n",
    "        # Creating Batch\n",
    "        image_mask = np.random.choice(X_train.shape[0],batchsize)\n",
    "        images_in = X_train[image_mask,:,:,:]\n",
    "        labels_in = Y_train[image_mask,:,:,:]\n",
    "        \n",
    "        # Traing Step\n",
    "        _, cost_val, summary = sess.run([train, cost, merged], feed_dict={images: images_in, true_out: labels_in, train_mode: True})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "        # No longer needed: cost_hist.append(cost_val)\n",
    "        if i%print_step == 0:\n",
    "            print (\"({}/{})\".format(i, num_batches).ljust(10) + ' | Cost: ' + str(cost_val))\n",
    "        \n",
    "    print \"\"\n",
    "    print \"Training Completed, storing weights\"\n",
    "    # Store Traing Output\n",
    "    net.save_npy(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "del net\n",
    "\n",
    "# Test\n",
    "test_img = np.expand_dims(X_val[100], axis = 0)\n",
    "test_ans = Y_val[100]\n",
    "\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=False\n",
    "config.gpu_options.per_process_gpu_memory_fraction= 1\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    sess = tf.Session(config=config)\n",
    "    images = tf.placeholder(tf.float32, [1, 160, 288, 3])\n",
    "    train_mode = tf.placeholder(tf.bool)\n",
    "    \n",
    "    net = deep3d.Deep3Dnet('./deep3d-save.npy')\n",
    "    net.build(images, train_mode)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    res, mask, up_3 = sess.run([net.prob, net.mask, net.up_3], feed_dict={images: test_img, train_mode: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.figure()\n",
    "\n",
    "print \"--- Input ---\"\n",
    "pyplot.imshow(test_img[0])\n",
    "pyplot.show()\n",
    "\n",
    "print \"--- GT ---\"\n",
    "pyplot.imshow(test_ans)\n",
    "pyplot.show()\n",
    "\n",
    "print \"--- Our result ---\"\n",
    "pyplot.imshow(res[0])\n",
    "pyplot.show()\n",
    "\n",
    "#pyplot.imsave('1.jpeg', test_img[0])\n",
    "#pyplot.imsave('2.jpeg', res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Disparity Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, axs = pyplot.subplots(6, 6, sharex='col', sharey='row')\n",
    "\n",
    "for i in range(33):\n",
    "    axs[i/6][i%6].imshow(mask[0,:,:,i],cmap=\"gray\",vmin=0.0, vmax=1.0)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_shift_channel = np.argmax(mask,axis = 3)\n",
    "max_shift_channel[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
