{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Toy TS Training for Deep3D+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple tester for the deep3d\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import Deep3D_saving as deep3d\n",
    "import utils\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ayyy\n",
      "Variable count:\n",
      "139067423\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Operation u'init' has been marked as not fetchable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e2238ef0a02a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# Run initializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m     \u001b[0mfetch_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds)\u001b[0m\n\u001b[1;32m    415\u001b[0m       \u001b[0mfetch_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/a/h/tlee05/Envs/deep-venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_assert_fetchable\u001b[0;34m(self, graph, op)\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m       raise ValueError(\n\u001b[0;32m--> 434\u001b[0;31m           'Operation %r has been marked as not fetchable.' % op.name)\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation u'init' has been marked as not fetchable."
     ]
    }
   ],
   "source": [
    "batchsize = 50\n",
    "num_epochs = 1\n",
    "print_step = 1\n",
    "\n",
    "\n",
    "left_dir = \"/a/data/deep3d_data/frames/train/left/\"\n",
    "right_dir = \"/a/data/deep3d_data/frames/train/right/\"\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    left_image_queue = tf.train.string_input_producer(\n",
    "      left_dir + tf.convert_to_tensor(os.listdir(left_dir)[0:200]),\n",
    "      shuffle=False, num_epochs=num_epochs)\n",
    "    right_image_queue = tf.train.string_input_producer(\n",
    "      right_dir + tf.convert_to_tensor(os.listdir(right_dir)[0:200]),\n",
    "      shuffle=False, num_epochs=num_epochs)\n",
    "\n",
    "    # use reader to read file\n",
    "    image_reader = tf.WholeFileReader()\n",
    "\n",
    "    _, left_image_raw = image_reader.read(left_image_queue)\n",
    "    left_image = tf.image.decode_jpeg(left_image_raw)\n",
    "    left_image = tf.cast(left_image, tf.float32)/255.0\n",
    "\n",
    "    _, right_image_raw = image_reader.read(right_image_queue)\n",
    "    right_image = tf.image.decode_jpeg(right_image_raw)\n",
    "    right_image = tf.cast(right_image, tf.float32)/255.0\n",
    "\n",
    "    left_image.set_shape([160,288,3])\n",
    "    right_image.set_shape([160,288,3])\n",
    "\n",
    "    # preprocess image\n",
    "    batch = tf.train.shuffle_batch([left_image, right_image], \n",
    "                                   batch_size = batchsize,\n",
    "                                   capacity = 12*batchsize,\n",
    "                                   num_threads = 1,\n",
    "                                   min_after_dequeue = 4*batchsize)\n",
    "\n",
    "\n",
    "# Define config for GPU memory debugging \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True  # Switch to True for dynamic memory allocation instead of TF hogging BS\n",
    "config.gpu_options.per_process_gpu_memory_fraction= 1  # Cap TF mem usage\n",
    "config.allow_soft_placement=True\n",
    "\n",
    "\n",
    "# Session\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# Placeholders\n",
    "images = tf.placeholder(tf.float32, [None, 160, 288, 3], name='input_batch')\n",
    "true_out = tf.placeholder(tf.float32, [None, 160, 288, 3] , name='ground_truth')\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')\n",
    "\n",
    "# Building Net based on VGG weights \n",
    "net = deep3d.Deep3Dnet('./vgg19.npy', dropout = 0.5)\n",
    "net.build(images, train_mode)\n",
    "\n",
    "\n",
    "# Print number of variables used: 143667240 variables, i.e. ideal size = 548MB\n",
    "print 'Variable count:'\n",
    "print(net.get_var_count())\n",
    "\n",
    "# Define Training Objectives\n",
    "with tf.variable_scope(\"Loss\"):\n",
    "    cost = tf.reduce_sum(tf.abs(net.prob - true_out))/batchsize\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=0.0014, beta1=0.84).minimize(cost)\n",
    "# with tf.control_dependencies([train]):\n",
    "#     training_op = tf.group(maintain_averages_op)\n",
    "\n",
    "# Run initializer \n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer()) \n",
    "coord = tf.train.Coordinator()\n",
    "queue_threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "\n",
    "# Track Cost    \n",
    "tf.summary.scalar('cost', cost)\n",
    "# tensorboard operations to compile summary and then write into logs\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter('./tensorboard_logs/', graph = sess.graph)\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "print \"\"\n",
    "print \"== Start training ==\"\n",
    "\n",
    "#base case\n",
    "next_batch = sess.run(batch)\n",
    "i=0\n",
    "try:\n",
    "    while not coord.should_stop():\n",
    "            # Traing Step\n",
    "        _, cost_val, next_batch, summary = sess.run([train, cost, batch, merged], \n",
    "                                                    feed_dict={images: next_batch[0], true_out: next_batch[1], train_mode: True})\n",
    "        writer.add_summary(summary, i)\n",
    "\n",
    "        # No longer needed: cost_hist.append(cost_val)\n",
    "        if i%print_step == 0:\n",
    "            print str(i) + ' | Cost: ' + str(cost_val)\n",
    "        i+=1\n",
    "\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('Done training -- epoch limit reached')\n",
    "\n",
    "finally:\n",
    "    # When done, ask the threads to stop.\n",
    "    coord.request_stop()\n",
    "    \n",
    "\n",
    "print \"\"\n",
    "print \"Training Completed, storing weights\"\n",
    "# Store Traing Output\n",
    "net.save_npy(sess)\n",
    "\n",
    "#termination stuff\n",
    "coord.join(queue_threads)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inria_file = '/a/data/deep3d_data/inria_data.h5'\n",
    "# # inria_file = 'data/inria_data.h5'\n",
    "# h5f = h5py.File(inria_file,'r')\n",
    "\n",
    "# X_train_0 = h5f['X_0'][:,10:170,16:304,:]\n",
    "# Y_train_0 = h5f['Y_0'][:,10:170,16:304,:]\n",
    "# X_train_1 = h5f['X_1'][:,10:170,16:304,:]\n",
    "# Y_train_1 = h5f['Y_1'][:,10:170,16:304,:]\n",
    "# X_train_2 = h5f['X_2'][:,10:170,16:304,:]\n",
    "# Y_train_2 = h5f['Y_2'][:,10:170,16:304,:]\n",
    "# X_train_3 = h5f['X_3'][:,10:170,16:304,:]\n",
    "# Y_train_3 = h5f['Y_3'][:,10:170,16:304,:]\n",
    "# X_train_4 = h5f['X_4'][:,10:170,16:304,:]\n",
    "# Y_train_4 = h5f['Y_4'][:,10:170,16:304,:]\n",
    "# X_train_5 = h5f['X_5'][:,10:170,16:304,:]\n",
    "# Y_train_5 = h5f['Y_5'][:,10:170,16:304,:]\n",
    "# X_train_6 = h5f['X_6'][:,10:170,16:304,:]\n",
    "# Y_train_6 = h5f['Y_6'][:,10:170,16:304,:]\n",
    "# #X_train_7 = h5f['X_7'][:,10:170,16:304,:]\n",
    "# #Y_train_7 = h5f['Y_7'][:,10:170,16:304,:]\n",
    "\n",
    "\n",
    "# X_val = h5f['X_7'][:,10:170,16:304,:]\n",
    "# Y_val = h5f['Y_7'][:,10:170,16:304,:]\n",
    "  \n",
    "# h5f.close()\n",
    "\n",
    "\n",
    "\n",
    "# # ------------------------------------------#\n",
    "# X_train = np.concatenate([X_train_0,X_train_1,X_train_2,X_train_3,X_train_4,X_train_5,X_train_6])\n",
    "# Y_train = np.concatenate([Y_train_0,Y_train_1,Y_train_2,Y_train_3,Y_train_4,Y_train_5,Y_train_6])\n",
    "\n",
    "# print \"Training Size:\" + str(X_train.shape)\n",
    "# print \"Validation Size:\" + str(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "test_img = np.expand_dims(X_val[155], axis = 0)\n",
    "test_ans = Y_val[155]\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    res, mask, up_conv = sess.run([net.prob, net.mask, net.up_conv], \n",
    "                                  feed_dict={images: test_img, train_mode: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print \"--- Input ---\"\n",
    "plt.imshow(test_img[0])\n",
    "plt.show()\n",
    "\n",
    "print \"--- GT ---\"\n",
    "plt.imshow(test_ans)\n",
    "plt.show()\n",
    "\n",
    "print \"--- Our result ---\"\n",
    "plt.imshow(res[0])\n",
    "plt.show()\n",
    "\n",
    "#pyplot.imsave('1.jpeg', test_img[0])\n",
    "#pyplot.imsave('2.jpeg', res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data from H5 Format for fast loading\n",
    "- Will eventually unit test dynamic CPU data loading pipeline here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Disparity Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(6, 6, sharex='col', sharey='row',figsize=(14,14))\n",
    "\n",
    "for i in range(33):\n",
    "    axs[i/6][i%6].imshow(mask[0,:,:,i],cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_shift_channel = np.argmax(mask,axis = 3)\n",
    "max_shift_channel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_mean = np.mean(mask[0], axis =(0,1))\n",
    "channel_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(channel_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "channel_act_mean = np.mean(up_conv[0], axis =(0,1))\n",
    "plt.plot(channel_act_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(up_conv[0,:,:,16].ravel(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for layer in range(33):\n",
    "    print layer\n",
    "    plt.imshow(up_conv[0,:,:,layer], cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
